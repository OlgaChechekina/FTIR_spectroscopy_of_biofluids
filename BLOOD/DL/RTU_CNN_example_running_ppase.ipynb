{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GaussianNoise, Conv1D, Flatten\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalStandardScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.mean_ = np.mean(X)\n",
    "        self.std_ = np.std(X)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return (X - self.mean_) / self.std_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>АЛТ_COBAS</th>\n",
       "      <th>АМИЛАЗА_ПАНКРЕАТИЧЕСКАЯ_COBAS</th>\n",
       "      <th>АСТ_COBAS</th>\n",
       "      <th>БЕЛОК_ОБЩИЙ_СЫВ_COBAS</th>\n",
       "      <th>БИЛИРУБИН_НЕПРЯМОЙ_COBAS</th>\n",
       "      <th>БИЛИРУБИН_ОБЩИЙ_2_COBAS</th>\n",
       "      <th>БИЛИРУБИН_ПРЯМОЙ_COBAS</th>\n",
       "      <th>ГАММА-ГТ_COBAS</th>\n",
       "      <th>ЖЕЛЕЗО_СЫВ_COBAS</th>\n",
       "      <th>КАЛЬЦИЙ_СЫВ_COBAS</th>\n",
       "      <th>...</th>\n",
       "      <th>1353.7843</th>\n",
       "      <th>1354.74853</th>\n",
       "      <th>1355.7127699999999</th>\n",
       "      <th>1356.6770000000001</th>\n",
       "      <th>1357.6412300000002</th>\n",
       "      <th>1358.60547</th>\n",
       "      <th>1359.5697</th>\n",
       "      <th>1360.53394</th>\n",
       "      <th>1361.4981699999998</th>\n",
       "      <th>1362.4624</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>21.400000</td>\n",
       "      <td>68.4</td>\n",
       "      <td>2.87</td>\n",
       "      <td>5.26</td>\n",
       "      <td>2.39</td>\n",
       "      <td>33.0</td>\n",
       "      <td>21.75</td>\n",
       "      <td>2.36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97444</td>\n",
       "      <td>1.17197</td>\n",
       "      <td>1.21980</td>\n",
       "      <td>1.18632</td>\n",
       "      <td>1.23533</td>\n",
       "      <td>1.40951</td>\n",
       "      <td>1.67764</td>\n",
       "      <td>2.09514</td>\n",
       "      <td>2.70435</td>\n",
       "      <td>3.41903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3786</th>\n",
       "      <td>18.100000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>70.8</td>\n",
       "      <td>4.23</td>\n",
       "      <td>6.79</td>\n",
       "      <td>2.56</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.06</td>\n",
       "      <td>2.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98935</td>\n",
       "      <td>1.24597</td>\n",
       "      <td>1.61786</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.30478</td>\n",
       "      <td>2.65579</td>\n",
       "      <td>3.19385</td>\n",
       "      <td>3.88026</td>\n",
       "      <td>4.61330</td>\n",
       "      <td>5.31514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824</th>\n",
       "      <td>23.300000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>19.800000</td>\n",
       "      <td>73.1</td>\n",
       "      <td>9.76</td>\n",
       "      <td>13.85</td>\n",
       "      <td>4.09</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.80</td>\n",
       "      <td>2.48</td>\n",
       "      <td>...</td>\n",
       "      <td>1.14454</td>\n",
       "      <td>1.27393</td>\n",
       "      <td>1.44144</td>\n",
       "      <td>1.58303</td>\n",
       "      <td>1.69189</td>\n",
       "      <td>1.79584</td>\n",
       "      <td>2.06795</td>\n",
       "      <td>2.75119</td>\n",
       "      <td>3.76612</td>\n",
       "      <td>4.74865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3831</th>\n",
       "      <td>15.100000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>74.0</td>\n",
       "      <td>3.37</td>\n",
       "      <td>5.68</td>\n",
       "      <td>2.31</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.88</td>\n",
       "      <td>2.41</td>\n",
       "      <td>...</td>\n",
       "      <td>1.05844</td>\n",
       "      <td>1.00934</td>\n",
       "      <td>1.13272</td>\n",
       "      <td>1.44539</td>\n",
       "      <td>1.84100</td>\n",
       "      <td>2.30015</td>\n",
       "      <td>2.88211</td>\n",
       "      <td>3.59298</td>\n",
       "      <td>4.39260</td>\n",
       "      <td>5.18190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4952</th>\n",
       "      <td>10.500000</td>\n",
       "      <td>53.0</td>\n",
       "      <td>19.700000</td>\n",
       "      <td>73.0</td>\n",
       "      <td>7.34</td>\n",
       "      <td>11.86</td>\n",
       "      <td>4.52</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.27</td>\n",
       "      <td>2.32</td>\n",
       "      <td>...</td>\n",
       "      <td>1.09299</td>\n",
       "      <td>1.22220</td>\n",
       "      <td>1.38399</td>\n",
       "      <td>1.43882</td>\n",
       "      <td>1.41184</td>\n",
       "      <td>1.50842</td>\n",
       "      <td>1.84966</td>\n",
       "      <td>2.40267</td>\n",
       "      <td>3.10426</td>\n",
       "      <td>3.87681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96717</th>\n",
       "      <td>18.500000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>18.800000</td>\n",
       "      <td>72.7</td>\n",
       "      <td>6.54</td>\n",
       "      <td>9.52</td>\n",
       "      <td>2.98</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.96</td>\n",
       "      <td>2.43</td>\n",
       "      <td>...</td>\n",
       "      <td>1.13963</td>\n",
       "      <td>1.34511</td>\n",
       "      <td>1.60684</td>\n",
       "      <td>1.88209</td>\n",
       "      <td>2.00320</td>\n",
       "      <td>1.93835</td>\n",
       "      <td>1.98480</td>\n",
       "      <td>2.45391</td>\n",
       "      <td>3.30606</td>\n",
       "      <td>4.26119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96721</th>\n",
       "      <td>11.100000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>72.8</td>\n",
       "      <td>6.30</td>\n",
       "      <td>9.70</td>\n",
       "      <td>3.40</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.29</td>\n",
       "      <td>2.33</td>\n",
       "      <td>...</td>\n",
       "      <td>1.18643</td>\n",
       "      <td>1.28860</td>\n",
       "      <td>1.37564</td>\n",
       "      <td>1.45492</td>\n",
       "      <td>1.47158</td>\n",
       "      <td>1.50406</td>\n",
       "      <td>1.80898</td>\n",
       "      <td>2.51398</td>\n",
       "      <td>3.42923</td>\n",
       "      <td>4.27672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98518</th>\n",
       "      <td>18.755435</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.703191</td>\n",
       "      <td>72.8</td>\n",
       "      <td>5.78</td>\n",
       "      <td>9.15</td>\n",
       "      <td>3.37</td>\n",
       "      <td>82.0</td>\n",
       "      <td>25.73</td>\n",
       "      <td>2.46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.84795</td>\n",
       "      <td>0.98657</td>\n",
       "      <td>1.17055</td>\n",
       "      <td>1.36923</td>\n",
       "      <td>1.50902</td>\n",
       "      <td>1.59533</td>\n",
       "      <td>1.84525</td>\n",
       "      <td>2.43253</td>\n",
       "      <td>3.26030</td>\n",
       "      <td>4.12724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98532</th>\n",
       "      <td>27.100000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.300000</td>\n",
       "      <td>73.4</td>\n",
       "      <td>5.10</td>\n",
       "      <td>7.90</td>\n",
       "      <td>2.80</td>\n",
       "      <td>40.0</td>\n",
       "      <td>22.02</td>\n",
       "      <td>2.45</td>\n",
       "      <td>...</td>\n",
       "      <td>1.15899</td>\n",
       "      <td>1.15537</td>\n",
       "      <td>1.03847</td>\n",
       "      <td>0.88431</td>\n",
       "      <td>0.86267</td>\n",
       "      <td>1.09400</td>\n",
       "      <td>1.53268</td>\n",
       "      <td>2.10503</td>\n",
       "      <td>2.79178</td>\n",
       "      <td>3.50557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98986</th>\n",
       "      <td>16.400000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>16.900000</td>\n",
       "      <td>69.9</td>\n",
       "      <td>10.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.87</td>\n",
       "      <td>2.26</td>\n",
       "      <td>...</td>\n",
       "      <td>1.17357</td>\n",
       "      <td>1.22974</td>\n",
       "      <td>1.33722</td>\n",
       "      <td>1.45608</td>\n",
       "      <td>1.56948</td>\n",
       "      <td>1.76551</td>\n",
       "      <td>2.14341</td>\n",
       "      <td>2.69234</td>\n",
       "      <td>3.33496</td>\n",
       "      <td>4.02220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 755 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            АЛТ_COBAS  АМИЛАЗА_ПАНКРЕАТИЧЕСКАЯ_COBAS  АСТ_COBAS  \\\n",
       "Unnamed: 0                                                        \n",
       "1897        20.000000                           17.0  21.400000   \n",
       "3786        18.100000                           40.0  15.300000   \n",
       "3824        23.300000                           31.0  19.800000   \n",
       "3831        15.100000                           19.0  15.300000   \n",
       "4952        10.500000                           53.0  19.700000   \n",
       "...               ...                            ...        ...   \n",
       "96717       18.500000                           21.0  18.800000   \n",
       "96721       11.100000                           18.0  13.400000   \n",
       "98518       18.755435                           21.0  20.703191   \n",
       "98532       27.100000                           30.0  20.300000   \n",
       "98986       16.400000                           24.0  16.900000   \n",
       "\n",
       "            БЕЛОК_ОБЩИЙ_СЫВ_COBAS  БИЛИРУБИН_НЕПРЯМОЙ_COBAS  \\\n",
       "Unnamed: 0                                                    \n",
       "1897                         68.4                      2.87   \n",
       "3786                         70.8                      4.23   \n",
       "3824                         73.1                      9.76   \n",
       "3831                         74.0                      3.37   \n",
       "4952                         73.0                      7.34   \n",
       "...                           ...                       ...   \n",
       "96717                        72.7                      6.54   \n",
       "96721                        72.8                      6.30   \n",
       "98518                        72.8                      5.78   \n",
       "98532                        73.4                      5.10   \n",
       "98986                        69.9                     10.00   \n",
       "\n",
       "            БИЛИРУБИН_ОБЩИЙ_2_COBAS  БИЛИРУБИН_ПРЯМОЙ_COBAS  ГАММА-ГТ_COBAS  \\\n",
       "Unnamed: 0                                                                    \n",
       "1897                           5.26                    2.39            33.0   \n",
       "3786                           6.79                    2.56            19.0   \n",
       "3824                          13.85                    4.09            19.0   \n",
       "3831                           5.68                    2.31            30.0   \n",
       "4952                          11.86                    4.52            18.0   \n",
       "...                             ...                     ...             ...   \n",
       "96717                          9.52                    2.98            18.0   \n",
       "96721                          9.70                    3.40            16.0   \n",
       "98518                          9.15                    3.37            82.0   \n",
       "98532                          7.90                    2.80            40.0   \n",
       "98986                         15.00                    5.00            10.0   \n",
       "\n",
       "            ЖЕЛЕЗО_СЫВ_COBAS  КАЛЬЦИЙ_СЫВ_COBAS  ...  1353.7843  1354.74853  \\\n",
       "Unnamed: 0                                       ...                          \n",
       "1897                   21.75               2.36  ...    0.97444     1.17197   \n",
       "3786                   14.06               2.30  ...    0.98935     1.24597   \n",
       "3824                   15.80               2.48  ...    1.14454     1.27393   \n",
       "3831                   10.88               2.41  ...    1.05844     1.00934   \n",
       "4952                    8.27               2.32  ...    1.09299     1.22220   \n",
       "...                      ...                ...  ...        ...         ...   \n",
       "96717                  15.96               2.43  ...    1.13963     1.34511   \n",
       "96721                  14.29               2.33  ...    1.18643     1.28860   \n",
       "98518                  25.73               2.46  ...    0.84795     0.98657   \n",
       "98532                  22.02               2.45  ...    1.15899     1.15537   \n",
       "98986                  14.87               2.26  ...    1.17357     1.22974   \n",
       "\n",
       "            1355.7127699999999  1356.6770000000001  1357.6412300000002  \\\n",
       "Unnamed: 0                                                               \n",
       "1897                   1.21980             1.18632             1.23533   \n",
       "3786                   1.61786             2.00000             2.30478   \n",
       "3824                   1.44144             1.58303             1.69189   \n",
       "3831                   1.13272             1.44539             1.84100   \n",
       "4952                   1.38399             1.43882             1.41184   \n",
       "...                        ...                 ...                 ...   \n",
       "96717                  1.60684             1.88209             2.00320   \n",
       "96721                  1.37564             1.45492             1.47158   \n",
       "98518                  1.17055             1.36923             1.50902   \n",
       "98532                  1.03847             0.88431             0.86267   \n",
       "98986                  1.33722             1.45608             1.56948   \n",
       "\n",
       "            1358.60547  1359.5697  1360.53394  1361.4981699999998  1362.4624  \n",
       "Unnamed: 0                                                                    \n",
       "1897           1.40951    1.67764     2.09514             2.70435    3.41903  \n",
       "3786           2.65579    3.19385     3.88026             4.61330    5.31514  \n",
       "3824           1.79584    2.06795     2.75119             3.76612    4.74865  \n",
       "3831           2.30015    2.88211     3.59298             4.39260    5.18190  \n",
       "4952           1.50842    1.84966     2.40267             3.10426    3.87681  \n",
       "...                ...        ...         ...                 ...        ...  \n",
       "96717          1.93835    1.98480     2.45391             3.30606    4.26119  \n",
       "96721          1.50406    1.80898     2.51398             3.42923    4.27672  \n",
       "98518          1.59533    1.84525     2.43253             3.26030    4.12724  \n",
       "98532          1.09400    1.53268     2.10503             2.79178    3.50557  \n",
       "98986          1.76551    2.14341     2.69234             3.33496    4.02220  \n",
       "\n",
       "[97 rows x 755 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = pd.read_csv(\"final.csv\").set_index(\"Unnamed: 0\")\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>648.9293700000001</th>\n",
       "      <th>649.8936</th>\n",
       "      <th>650.85784</th>\n",
       "      <th>651.82207</th>\n",
       "      <th>652.7863</th>\n",
       "      <th>653.75054</th>\n",
       "      <th>654.71477</th>\n",
       "      <th>655.67901</th>\n",
       "      <th>656.64324</th>\n",
       "      <th>657.60747</th>\n",
       "      <th>...</th>\n",
       "      <th>1353.7843</th>\n",
       "      <th>1354.74853</th>\n",
       "      <th>1355.7127699999999</th>\n",
       "      <th>1356.6770000000001</th>\n",
       "      <th>1357.6412300000002</th>\n",
       "      <th>1358.60547</th>\n",
       "      <th>1359.5697</th>\n",
       "      <th>1360.53394</th>\n",
       "      <th>1361.4981699999998</th>\n",
       "      <th>1362.4624</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>-1.90382</td>\n",
       "      <td>-1.94169</td>\n",
       "      <td>-1.64775</td>\n",
       "      <td>-1.53010</td>\n",
       "      <td>-1.82676</td>\n",
       "      <td>-2.22468</td>\n",
       "      <td>-2.36547</td>\n",
       "      <td>-2.35905</td>\n",
       "      <td>-2.41824</td>\n",
       "      <td>-2.41441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97444</td>\n",
       "      <td>1.17197</td>\n",
       "      <td>1.21980</td>\n",
       "      <td>1.18632</td>\n",
       "      <td>1.23533</td>\n",
       "      <td>1.40951</td>\n",
       "      <td>1.67764</td>\n",
       "      <td>2.09514</td>\n",
       "      <td>2.70435</td>\n",
       "      <td>3.41903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3786</th>\n",
       "      <td>-2.15201</td>\n",
       "      <td>-2.51687</td>\n",
       "      <td>-2.51557</td>\n",
       "      <td>-2.12705</td>\n",
       "      <td>-1.49084</td>\n",
       "      <td>-0.77886</td>\n",
       "      <td>-0.21228</td>\n",
       "      <td>-0.00488</td>\n",
       "      <td>-0.35919</td>\n",
       "      <td>-1.30331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98935</td>\n",
       "      <td>1.24597</td>\n",
       "      <td>1.61786</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.30478</td>\n",
       "      <td>2.65579</td>\n",
       "      <td>3.19385</td>\n",
       "      <td>3.88026</td>\n",
       "      <td>4.61330</td>\n",
       "      <td>5.31514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824</th>\n",
       "      <td>-1.27152</td>\n",
       "      <td>-1.02976</td>\n",
       "      <td>-0.87264</td>\n",
       "      <td>-0.83898</td>\n",
       "      <td>-0.82996</td>\n",
       "      <td>-0.89339</td>\n",
       "      <td>-1.24503</td>\n",
       "      <td>-1.76623</td>\n",
       "      <td>-2.06413</td>\n",
       "      <td>-2.04146</td>\n",
       "      <td>...</td>\n",
       "      <td>1.14454</td>\n",
       "      <td>1.27393</td>\n",
       "      <td>1.44144</td>\n",
       "      <td>1.58303</td>\n",
       "      <td>1.69189</td>\n",
       "      <td>1.79584</td>\n",
       "      <td>2.06795</td>\n",
       "      <td>2.75119</td>\n",
       "      <td>3.76612</td>\n",
       "      <td>4.74865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3831</th>\n",
       "      <td>-0.95296</td>\n",
       "      <td>-1.01604</td>\n",
       "      <td>-0.99327</td>\n",
       "      <td>-1.03937</td>\n",
       "      <td>-1.07597</td>\n",
       "      <td>-0.91293</td>\n",
       "      <td>-0.55450</td>\n",
       "      <td>-0.29493</td>\n",
       "      <td>-0.45495</td>\n",
       "      <td>-0.99243</td>\n",
       "      <td>...</td>\n",
       "      <td>1.05844</td>\n",
       "      <td>1.00934</td>\n",
       "      <td>1.13272</td>\n",
       "      <td>1.44539</td>\n",
       "      <td>1.84100</td>\n",
       "      <td>2.30015</td>\n",
       "      <td>2.88211</td>\n",
       "      <td>3.59298</td>\n",
       "      <td>4.39260</td>\n",
       "      <td>5.18190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4952</th>\n",
       "      <td>-2.96050</td>\n",
       "      <td>-2.54587</td>\n",
       "      <td>-1.89239</td>\n",
       "      <td>-1.13672</td>\n",
       "      <td>-0.70192</td>\n",
       "      <td>-0.79351</td>\n",
       "      <td>-1.21978</td>\n",
       "      <td>-1.67505</td>\n",
       "      <td>-2.11074</td>\n",
       "      <td>-2.67038</td>\n",
       "      <td>...</td>\n",
       "      <td>1.09299</td>\n",
       "      <td>1.22220</td>\n",
       "      <td>1.38399</td>\n",
       "      <td>1.43882</td>\n",
       "      <td>1.41184</td>\n",
       "      <td>1.50842</td>\n",
       "      <td>1.84966</td>\n",
       "      <td>2.40267</td>\n",
       "      <td>3.10426</td>\n",
       "      <td>3.87681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96717</th>\n",
       "      <td>-2.21033</td>\n",
       "      <td>-1.82475</td>\n",
       "      <td>-1.49770</td>\n",
       "      <td>-1.42195</td>\n",
       "      <td>-1.56139</td>\n",
       "      <td>-1.64418</td>\n",
       "      <td>-1.58581</td>\n",
       "      <td>-1.57968</td>\n",
       "      <td>-1.71088</td>\n",
       "      <td>-1.87181</td>\n",
       "      <td>...</td>\n",
       "      <td>1.13963</td>\n",
       "      <td>1.34511</td>\n",
       "      <td>1.60684</td>\n",
       "      <td>1.88209</td>\n",
       "      <td>2.00320</td>\n",
       "      <td>1.93835</td>\n",
       "      <td>1.98480</td>\n",
       "      <td>2.45391</td>\n",
       "      <td>3.30606</td>\n",
       "      <td>4.26119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96721</th>\n",
       "      <td>-1.34928</td>\n",
       "      <td>-1.27609</td>\n",
       "      <td>-1.29154</td>\n",
       "      <td>-1.35558</td>\n",
       "      <td>-1.36363</td>\n",
       "      <td>-1.25700</td>\n",
       "      <td>-1.14322</td>\n",
       "      <td>-1.06728</td>\n",
       "      <td>-0.99232</td>\n",
       "      <td>-1.02884</td>\n",
       "      <td>...</td>\n",
       "      <td>1.18643</td>\n",
       "      <td>1.28860</td>\n",
       "      <td>1.37564</td>\n",
       "      <td>1.45492</td>\n",
       "      <td>1.47158</td>\n",
       "      <td>1.50406</td>\n",
       "      <td>1.80898</td>\n",
       "      <td>2.51398</td>\n",
       "      <td>3.42923</td>\n",
       "      <td>4.27672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98518</th>\n",
       "      <td>-1.81876</td>\n",
       "      <td>-1.82350</td>\n",
       "      <td>-1.65203</td>\n",
       "      <td>-1.51259</td>\n",
       "      <td>-1.42031</td>\n",
       "      <td>-1.21150</td>\n",
       "      <td>-0.92912</td>\n",
       "      <td>-0.76171</td>\n",
       "      <td>-0.78496</td>\n",
       "      <td>-0.95945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.84795</td>\n",
       "      <td>0.98657</td>\n",
       "      <td>1.17055</td>\n",
       "      <td>1.36923</td>\n",
       "      <td>1.50902</td>\n",
       "      <td>1.59533</td>\n",
       "      <td>1.84525</td>\n",
       "      <td>2.43253</td>\n",
       "      <td>3.26030</td>\n",
       "      <td>4.12724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98532</th>\n",
       "      <td>-3.43209</td>\n",
       "      <td>-3.62686</td>\n",
       "      <td>-3.35639</td>\n",
       "      <td>-2.97174</td>\n",
       "      <td>-2.59258</td>\n",
       "      <td>-2.29247</td>\n",
       "      <td>-2.04005</td>\n",
       "      <td>-1.88300</td>\n",
       "      <td>-2.19528</td>\n",
       "      <td>-3.02117</td>\n",
       "      <td>...</td>\n",
       "      <td>1.15899</td>\n",
       "      <td>1.15537</td>\n",
       "      <td>1.03847</td>\n",
       "      <td>0.88431</td>\n",
       "      <td>0.86267</td>\n",
       "      <td>1.09400</td>\n",
       "      <td>1.53268</td>\n",
       "      <td>2.10503</td>\n",
       "      <td>2.79178</td>\n",
       "      <td>3.50557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98986</th>\n",
       "      <td>-3.24201</td>\n",
       "      <td>-3.18120</td>\n",
       "      <td>-2.81763</td>\n",
       "      <td>-2.37839</td>\n",
       "      <td>-2.15600</td>\n",
       "      <td>-2.08457</td>\n",
       "      <td>-1.97261</td>\n",
       "      <td>-1.85463</td>\n",
       "      <td>-1.87374</td>\n",
       "      <td>-2.04227</td>\n",
       "      <td>...</td>\n",
       "      <td>1.17357</td>\n",
       "      <td>1.22974</td>\n",
       "      <td>1.33722</td>\n",
       "      <td>1.45608</td>\n",
       "      <td>1.56948</td>\n",
       "      <td>1.76551</td>\n",
       "      <td>2.14341</td>\n",
       "      <td>2.69234</td>\n",
       "      <td>3.33496</td>\n",
       "      <td>4.02220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 741 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            648.9293700000001  649.8936  650.85784  651.82207  652.7863  \\\n",
       "Unnamed: 0                                                                \n",
       "1897                 -1.90382  -1.94169   -1.64775   -1.53010  -1.82676   \n",
       "3786                 -2.15201  -2.51687   -2.51557   -2.12705  -1.49084   \n",
       "3824                 -1.27152  -1.02976   -0.87264   -0.83898  -0.82996   \n",
       "3831                 -0.95296  -1.01604   -0.99327   -1.03937  -1.07597   \n",
       "4952                 -2.96050  -2.54587   -1.89239   -1.13672  -0.70192   \n",
       "...                       ...       ...        ...        ...       ...   \n",
       "96717                -2.21033  -1.82475   -1.49770   -1.42195  -1.56139   \n",
       "96721                -1.34928  -1.27609   -1.29154   -1.35558  -1.36363   \n",
       "98518                -1.81876  -1.82350   -1.65203   -1.51259  -1.42031   \n",
       "98532                -3.43209  -3.62686   -3.35639   -2.97174  -2.59258   \n",
       "98986                -3.24201  -3.18120   -2.81763   -2.37839  -2.15600   \n",
       "\n",
       "            653.75054  654.71477  655.67901  656.64324  657.60747  ...  \\\n",
       "Unnamed: 0                                                         ...   \n",
       "1897         -2.22468   -2.36547   -2.35905   -2.41824   -2.41441  ...   \n",
       "3786         -0.77886   -0.21228   -0.00488   -0.35919   -1.30331  ...   \n",
       "3824         -0.89339   -1.24503   -1.76623   -2.06413   -2.04146  ...   \n",
       "3831         -0.91293   -0.55450   -0.29493   -0.45495   -0.99243  ...   \n",
       "4952         -0.79351   -1.21978   -1.67505   -2.11074   -2.67038  ...   \n",
       "...               ...        ...        ...        ...        ...  ...   \n",
       "96717        -1.64418   -1.58581   -1.57968   -1.71088   -1.87181  ...   \n",
       "96721        -1.25700   -1.14322   -1.06728   -0.99232   -1.02884  ...   \n",
       "98518        -1.21150   -0.92912   -0.76171   -0.78496   -0.95945  ...   \n",
       "98532        -2.29247   -2.04005   -1.88300   -2.19528   -3.02117  ...   \n",
       "98986        -2.08457   -1.97261   -1.85463   -1.87374   -2.04227  ...   \n",
       "\n",
       "            1353.7843  1354.74853  1355.7127699999999  1356.6770000000001  \\\n",
       "Unnamed: 0                                                                  \n",
       "1897          0.97444     1.17197             1.21980             1.18632   \n",
       "3786          0.98935     1.24597             1.61786             2.00000   \n",
       "3824          1.14454     1.27393             1.44144             1.58303   \n",
       "3831          1.05844     1.00934             1.13272             1.44539   \n",
       "4952          1.09299     1.22220             1.38399             1.43882   \n",
       "...               ...         ...                 ...                 ...   \n",
       "96717         1.13963     1.34511             1.60684             1.88209   \n",
       "96721         1.18643     1.28860             1.37564             1.45492   \n",
       "98518         0.84795     0.98657             1.17055             1.36923   \n",
       "98532         1.15899     1.15537             1.03847             0.88431   \n",
       "98986         1.17357     1.22974             1.33722             1.45608   \n",
       "\n",
       "            1357.6412300000002  1358.60547  1359.5697  1360.53394  \\\n",
       "Unnamed: 0                                                          \n",
       "1897                   1.23533     1.40951    1.67764     2.09514   \n",
       "3786                   2.30478     2.65579    3.19385     3.88026   \n",
       "3824                   1.69189     1.79584    2.06795     2.75119   \n",
       "3831                   1.84100     2.30015    2.88211     3.59298   \n",
       "4952                   1.41184     1.50842    1.84966     2.40267   \n",
       "...                        ...         ...        ...         ...   \n",
       "96717                  2.00320     1.93835    1.98480     2.45391   \n",
       "96721                  1.47158     1.50406    1.80898     2.51398   \n",
       "98518                  1.50902     1.59533    1.84525     2.43253   \n",
       "98532                  0.86267     1.09400    1.53268     2.10503   \n",
       "98986                  1.56948     1.76551    2.14341     2.69234   \n",
       "\n",
       "            1361.4981699999998  1362.4624  \n",
       "Unnamed: 0                                 \n",
       "1897                   2.70435    3.41903  \n",
       "3786                   4.61330    5.31514  \n",
       "3824                   3.76612    4.74865  \n",
       "3831                   4.39260    5.18190  \n",
       "4952                   3.10426    3.87681  \n",
       "...                        ...        ...  \n",
       "96717                  3.30606    4.26119  \n",
       "96721                  3.42923    4.27672  \n",
       "98518                  3.26030    4.12724  \n",
       "98532                  2.79178    3.50557  \n",
       "98986                  3.33496    4.02220  \n",
       "\n",
       "[97 rows x 741 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = final.iloc[:, 14:].copy()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0\n",
       "1897     54.0\n",
       "3786     99.0\n",
       "3824     57.0\n",
       "3831     98.0\n",
       "4952     70.0\n",
       "         ... \n",
       "96717    54.0\n",
       "96721    60.0\n",
       "98518    86.0\n",
       "98532    60.0\n",
       "98986    52.0\n",
       "Name: ФОСФАТАЗА_ЩЕЛОЧНАЯ_ОБЩАЯ_COBAS, Length: 97, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = final[\"ФОСФАТАЗА_ЩЕЛОЧНАЯ_ОБЩАЯ_COBAS\"]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataaugment(x, betashift = 0.05, slopeshift = 0.05,multishift = 0.05):\n",
    "    beta = np.random.random(size=(x.shape[0],1))*2*betashift-betashift\n",
    "    slope = np.random.random(size=(x.shape[0],1))*2*slopeshift-slopeshift + 1\n",
    "    axis = np.array(range(x.shape[1]))/float(x.shape[1])\n",
    "    offset = slope*(axis) + beta - axis - slope/2. + 0.5\n",
    "    multi = np.random.random(size=(x.shape[0],1))*2*multishift-multishift + 1\n",
    "    x = multi*x + offset\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_data, trigly, test_size=0.2, random_state=42)\n",
    "\n",
    "class DataGenerator:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        # Define the hyperparameters and their possible values\n",
    "        self.dense_values = [128, 256]\n",
    "        self.dropout_values = [0.2, 0.4]\n",
    "        self.activation_functions = ['relu']\n",
    "        self.learning_rates = [0.001]\n",
    "        self.batch_sizes = [16, 32]\n",
    "        self.C1_K_values = [8]\n",
    "        self.C1_S_values = [32]\n",
    "        self.C2_K_values = [16]\n",
    "        self.C2_S_values = [32]\n",
    "        \n",
    "    def param_generator(self):\n",
    "        for dense in self.dense_values:\n",
    "            for dropout in self.dropout_values:\n",
    "                for activation in self.activation_functions:\n",
    "                    for learning_rate in self.learning_rates:\n",
    "                        for batch_size in self.batch_sizes:\n",
    "                            for C1_K in self.C1_K_values:\n",
    "                                for C1_S in self.C1_S_values:\n",
    "                                    for C2_K in self.C2_K_values:\n",
    "                                        for C2_S in self.C2_S_values:\n",
    "                                            yield {'dense': dense, 'dropout': dropout, \n",
    "                                                   'activation': activation, 'learning_rate': learning_rate, \n",
    "                                                   'batch_size': batch_size, 'C1_K': C1_K, 'C1_S': C1_S, \n",
    "                                                   'C2_K': C2_K, 'C2_S': C2_S}\n",
    "\n",
    "    def create_model(self, params, input_dim):\n",
    "        model = Sequential()\n",
    "        model.add(GaussianNoise(0.05, input_shape=(input_dim,)))\n",
    "        model.add(Reshape((input_dim, 1) ))\n",
    "        model.add(Conv1D(params['C1_K'], (params['C1_S']), activation=params['activation']))\n",
    "        model.add(Conv1D(params['C2_K'], (params['C2_S']), activation=params['activation']))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(params['dropout']))\n",
    "        model.add(Dense(params['dense'], activation=params['activation']))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(lr=params['learning_rate']))\n",
    "        return model\n",
    "\n",
    "    def fit_generator(self, n_splits=5, shuffle=True):\n",
    "        kf = KFold(n_splits=n_splits, shuffle=shuffle)\n",
    "        for params in self.param_generator():\n",
    "            print(f\"Fitting model with hyperparameters: {params}\")\n",
    "            scores = []\n",
    "            for train_index, test_index in kf.split(self.X):\n",
    "                X_train, X_test = self.X[train_index], self.X[test_index]\n",
    "                y_train, y_test = self.y[train_index], self.y[test_index]\n",
    "                model = self.create_model(params, self.X.shape[1])\n",
    "                model.fit(X_train, y_train, epochs=10, batch_size=params['batch_size'], verbose=0)\n",
    "                score = model.evaluate(X_test, y_test, verbose=0)\n",
    "                scores.append(score)\n",
    "            mean_score = np.mean(scores)\n",
    "            yield {'hyperparameters': params, 'mean_test_score': mean_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9700, 741)\n",
      "(9700,)\n",
      "Fitting model with hyperparameters: {'dense': 128, 'dropout': 0.2, 'activation': 'relu', 'learning_rate': 0.001, 'batch_size': 16, 'C1_K': 8, 'C1_S': 32, 'C2_K': 16, 'C2_S': 32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olaga\\Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model with hyperparameters: {'dense': 128, 'dropout': 0.2, 'activation': 'relu', 'learning_rate': 0.001, 'batch_size': 32, 'C1_K': 8, 'C1_S': 32, 'C2_K': 16, 'C2_S': 32}\n",
      "Fitting model with hyperparameters: {'dense': 128, 'dropout': 0.4, 'activation': 'relu', 'learning_rate': 0.001, 'batch_size': 16, 'C1_K': 8, 'C1_S': 32, 'C2_K': 16, 'C2_S': 32}\n",
      "Fitting model with hyperparameters: {'dense': 128, 'dropout': 0.4, 'activation': 'relu', 'learning_rate': 0.001, 'batch_size': 32, 'C1_K': 8, 'C1_S': 32, 'C2_K': 16, 'C2_S': 32}\n",
      "Fitting model with hyperparameters: {'dense': 256, 'dropout': 0.2, 'activation': 'relu', 'learning_rate': 0.001, 'batch_size': 16, 'C1_K': 8, 'C1_S': 32, 'C2_K': 16, 'C2_S': 32}\n",
      "Fitting model with hyperparameters: {'dense': 256, 'dropout': 0.2, 'activation': 'relu', 'learning_rate': 0.001, 'batch_size': 32, 'C1_K': 8, 'C1_S': 32, 'C2_K': 16, 'C2_S': 32}\n",
      "Fitting model with hyperparameters: {'dense': 256, 'dropout': 0.4, 'activation': 'relu', 'learning_rate': 0.001, 'batch_size': 16, 'C1_K': 8, 'C1_S': 32, 'C2_K': 16, 'C2_S': 32}\n",
      "Fitting model with hyperparameters: {'dense': 256, 'dropout': 0.4, 'activation': 'relu', 'learning_rate': 0.001, 'batch_size': 32, 'C1_K': 8, 'C1_S': 32, 'C2_K': 16, 'C2_S': 32}\n",
      "                                     hyperparameters  mean_test_score\n",
      "0  {'dense': 128, 'dropout': 0.2, 'activation': '...         1.753377\n",
      "1  {'dense': 128, 'dropout': 0.2, 'activation': '...         1.331538\n",
      "2  {'dense': 128, 'dropout': 0.4, 'activation': '...         2.200967\n",
      "3  {'dense': 128, 'dropout': 0.4, 'activation': '...         2.094548\n",
      "4  {'dense': 256, 'dropout': 0.2, 'activation': '...         1.719446\n",
      "5  {'dense': 256, 'dropout': 0.2, 'activation': '...         1.487346\n",
      "6  {'dense': 256, 'dropout': 0.4, 'activation': '...         1.532562\n",
      "7  {'dense': 256, 'dropout': 0.4, 'activation': '...         1.631479\n"
     ]
    }
   ],
   "source": [
    "X = final.iloc[:, 14:].copy()\n",
    "y = final[\"ЖЕЛЕЗО_СЫВ_COBAS\"]\n",
    "X = X.reset_index(drop=True)\n",
    "shift = np.std(X)*0.1\n",
    "X_aug = pd.DataFrame(np.repeat(X.to_numpy(), repeats=100, axis=0))\n",
    "X_aug.index = np.arange(len(X_aug))\n",
    "X_aug = dataaugment(X_aug, betashift=0.1, slopeshift=0.05, multishift=0.1)\n",
    "X_aug = pd.DataFrame(X_aug)\n",
    "\n",
    "y_aug = np.repeat(y.to_numpy(), repeats=100, axis=0)\n",
    "y_aug = pd.Series(y_aug, index=np.arange(len(y_aug)))\n",
    "\n",
    "print(X_aug.shape)  # should be (7700, 741)\n",
    "print(y_aug.shape) \n",
    "\n",
    "pd.DataFrame(y_aug).to_csv(\"y_aug_Fe.csv\")\n",
    "\n",
    "X_datan = X_aug.to_numpy()\n",
    "triglyn = y_aug.to_numpy()           \n",
    "data_generator = DataGenerator(X_datan, triglyn)\n",
    "results = pd.DataFrame(data_generator.fit_generator())\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper2 = pd.DataFrame()\n",
    "for row in results.iloc[:,0]:\n",
    "    hyper2 = hyper2.append(row, ignore_index=True)\n",
    "hyper2 = hyper2.iloc[:, [0,1,4]]\n",
    "#hyper2 = hyper2.iloc[:, :-1]\n",
    "hypers2 = pd.concat([hyper2, results.iloc[:, -1]], axis = 1)\n",
    "hypers2 = hypers2.sort_values(by = \"mean_test_score\")\n",
    "hypers2.to_csv(\"hyperparams_Fe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dense</th>\n",
       "      <th>dropout</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.331538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>256.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.487346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>256.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.532562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>256.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.631479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>256.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.719446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.753377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.094548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.200967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dense  dropout  batch_size  mean_test_score\n",
       "1  128.0      0.2        32.0         1.331538\n",
       "5  256.0      0.2        32.0         1.487346\n",
       "6  256.0      0.4        16.0         1.532562\n",
       "7  256.0      0.4        32.0         1.631479\n",
       "4  256.0      0.2        16.0         1.719446\n",
       "0  128.0      0.2        16.0         1.753377\n",
       "3  128.0      0.4        32.0         2.094548\n",
       "2  128.0      0.4        16.0         2.200967"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypers2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
